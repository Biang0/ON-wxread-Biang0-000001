# main.py ä¸»é€»è¾‘ï¼šåŒ…æ‹¬å­—æ®µæ‹¼æ¥ã€æ¨¡æ‹Ÿè¯·æ±‚
import json
import time
import random
import logging
import hashlib
import requests
import urllib.parse
import os  # è¯»å–ç¯å¢ƒå˜é‡
from config import get_book_info, REQUEST_DATA, HEADERS, COOKIES, PUSH_METHOD, READ_NUM
from push import push

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)-8s - %(message)s",
    handlers=[logging.FileHandler("wechat_read.log"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)

# API åœ°å€
READ_URL = "https://weread.qq.com/web/book/read"
RENEW_URL = "https://weread.qq.com/web/login/renewal"
KEY = os.getenv("WXREAD_KEY")  # ä»ç¯å¢ƒå˜é‡è·å–å¯†é’¥

def get_beijing_time():
    """è·å–åŒ—äº¬æ—¶é—´"""
    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time() + 8 * 3600))

def encode_data(params: dict) -> str:
    """å¯¹å‚æ•°è¿›è¡Œ URL ç¼–ç """
    return "&".join([f"{k}={urllib.parse.quote(str(v), safe='')}" for k, v in sorted(params.items())])

def calculate_hash(data: str) -> str:
    """è®¡ç®—è‡ªå®šä¹‰å“ˆå¸Œå€¼"""
    _7032f5 = 0x15051505
    _cc1055 = _7032f5
    length = len(data)
    index = length - 1
    while index > 0:
        _7032f5 = (_7032f5 ^ (ord(data[index]) << ((length - index) % 30))) & 0x7FFFFFFF
        _cc1055 = (_cc1055 ^ (ord(data[index - 1]) << (index % 30))) & 0x7FFFFFFF
        index -= 2
    return hex(_7032f5 + _cc1055)[2:].lower()

def get_wr_skey():
    """åˆ·æ–° cookie å¯†é’¥"""
    COOKIE_DATA = {"rq": "%2Fweb%2Fbook%2Fread"}
    try:
        response = requests.post(
            RENEW_URL,
            headers=HEADERS,
            cookies=COOKIES,
            data=json.dumps(COOKIE_DATA, separators=(',', ':'))
        )
        return response.cookies.get("wr_skey", "")[:8]
    except Exception as e:
        logger.error(f"âŒ åˆ·æ–°å¯†é’¥å¤±è´¥: {str(e)}")
        return None

def main():
    try:
        # è·å–ä¹¦ç±ä¿¡æ¯å¹¶æ ¼å¼åŒ–æ—¥å¿—
        selected_book, selected_b, book_mapping = get_book_info()  # å‡è®¾ get_book_info è¿”å›æ˜ å°„è¡¨
        logger.info("ä¹¦ç±æ˜ å°„è¡¨ï¼š")
        logger.info(json.dumps(book_mapping, indent=2, ensure_ascii=False))
        
        REQUEST_DATA["b"] = selected_b
        logger.info(f"ğŸ¯ é€‰å®šä¹¦ç±: {selected_book} (bå€¼: {selected_b})")
        total_read_time = 0.0
        index = 1

        while index <= READ_NUM:
            try:
                READ_COMPLETE_HEADER = os.getenv("READ_COMPLETE_HEADER") or "ğŸ‰ å¾®ä¿¡é˜…è¯»å·²å®Œæˆï¼"
                
                # æ›´æ–°åŠ¨æ€å‚æ•°
                REQUEST_DATA["ct"] = int(time.time())
                REQUEST_DATA["ts"] = int(time.time() * 1000)
                REQUEST_DATA["rn"] = random.randint(0, 1000)
                REQUEST_DATA["sg"] = hashlib.sha256(
                    f"{REQUEST_DATA['ts']}{REQUEST_DATA['rn']}{KEY}".encode()
                ).hexdigest()
                REQUEST_DATA["s"] = calculate_hash(encode_data(REQUEST_DATA))

                logger.info(f"â±ï¸ å°è¯•ç¬¬ {index} æ¬¡é˜…è¯»...")
                response = requests.post(
                    READ_URL,
                    headers=HEADERS,
                    cookies=COOKIES,
                    data=json.dumps(REQUEST_DATA, separators=(",", ":"))
                )
                resData = response.json()

                if 'succ' in resData:
                    total_read_time += 0.5
                    index += 1
                    time.sleep(15)  # ä¼˜åŒ–é—´éš”æ—¶é—´
                    logger.info(f"âœ… é˜…è¯»æˆåŠŸï¼Œå½“å‰ç´¯è®¡è¿›åº¦ï¼š{total_read_time:.1f} åˆ†é’Ÿ")
                else:
                    logger.warning("âŒ Cookie å¯èƒ½å·²è¿‡æœŸï¼Œå°è¯•åˆ·æ–°...")
                    new_skey = get_wr_skey()
                    if new_skey:
                        COOKIES['wr_skey'] = new_skey
                        logger.info(f"âœ… å¯†é’¥åˆ·æ–°æˆåŠŸï¼Œæ–°å¯†é’¥ï¼š{new_skey}")
                        logger.info("ğŸ”„ é‡æ–°å°è¯•æœ¬æ¬¡é˜…è¯»ã€‚")
                    else:
                        raise Exception("âŒ æ— æ³•è·å–æ–°å¯†é’¥ï¼Œç»ˆæ­¢è¿è¡Œã€‚")
                REQUEST_DATA.pop('s')

            except requests.exceptions.JSONDecodeError as e:
                logger.error(f"âŒ å“åº”è§£æå¤±è´¥: {str(e)}")
            except requests.exceptions.RequestException as e:
                logger.error(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
            except KeyError as e:
                logger.error(f"âŒ å“åº”ç¼ºå°‘å…³é”®å­—æ®µ: {str(e)}")
            except Exception as e:
                logger.error(f"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
                break

        logger.info("ğŸ‰ é˜…è¯»ä»»åŠ¡å®Œæˆï¼")

        # å‘é€æ¨é€é€šçŸ¥
        if PUSH_METHOD:
            try:
                message = (
                    f"{READ_COMPLETE_HEADER}\n\n"
                    f"ğŸ“š ä¹¦ç±ï¼šã€Š{selected_book}ã€‹\n"
                    f"â±ï¸ é˜…è¯»æ—¶é•¿ï¼š{total_read_time:.1f} åˆ†é’Ÿ\n"
                    f"ğŸ“… å®Œæˆæ—¶é—´ï¼š{get_beijing_time()}"
                )
                push(message, PUSH_METHOD)
                logger.info(f"âœ… æ¨é€æˆåŠŸ: {READ_COMPLETE_HEADER}")
            except Exception as e:
                logger.error(f"âŒ æ¨é€å¤±è´¥: {str(e)}")

        # è®°å½•è¿è¡Œæ•°æ®åˆ°æ–‡ä»¶
        log_path = "run_data.log"
        try:
            with open(log_path, "a", encoding="utf-8") as file:
                file.write(f"è¿è¡Œæ—¶é—´: {get_beijing_time()}\n")
                file.write(f"é€‰å®šä¹¦ç±: ã€Š{selected_book}ã€‹\n")
                file.write(f"é˜…è¯»æ—¶é•¿: {total_read_time:.1f} åˆ†é’Ÿ\n")
                file.write("-" * 50 + "\n")
            logger.info(f"âœ… è¿è¡Œæ•°æ®å·²è®°å½•åˆ° {log_path}")
        except Exception as e:
            logger.error(f"âŒ è®°å½•è¿è¡Œæ•°æ®å¤±è´¥: {str(e)}")
            raise

    except Exception as e:
        logger.error(f"âŒ ä¸»ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
        if PUSH_METHOD:
            push(f"âŒ ä»»åŠ¡å¤±è´¥: {str(e)}", PUSH_METHOD)
        raise

if __name__ == "__main__":
    main()
